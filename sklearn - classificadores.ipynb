{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aula https://www.youtube.com/watch?v=du_HuGgABtw&feature=youtu.be\n",
    "#https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "\n",
    "import sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# the training data folder must be passed as first argument\n",
    "movie_reviews_data_folder = r\"./data\"\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "print(\"n_samples: %d\" % len(dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1]\n",
      "neg ['pos']\n"
     ]
    }
   ],
   "source": [
    "#====================================================================\n",
    "#dataset.data         ## textos das análises \n",
    "#dataset.target       ## 0,1 onde: 0 análise negativa, 1 análise positiva\n",
    "#dataset.target_names ## nome das categorias (pastas que separam textos em neg e pos) \n",
    "#====================================================================\n",
    "print (dataset.target[0]  ,  dataset.target[-1:])    \n",
    "print (dataset.target_names[0]  ,  dataset.target_names[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(dataset.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "clf = MultinomialNB().fit(X_train_tfidf, dataset.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "docs_new = [\"great secret , an event which will change both of their lives forever\"]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'great secret , an event which will change both of their lives forever' => pos\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, dataset.target_names[category]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#\n",
    "#  MESMA COISA, MAS AGORA COM Pipeline\n",
    "#\n",
    "#\n",
    "#===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hical user interface when we use our computers ! \\n' 1\n",
      "b'character , but hartman leaves him in the dust . \\n' 0\n"
     ]
    }
   ],
   "source": [
    "#====================================================================\n",
    "#dvamos separar 30% para teste\n",
    "# X = texto, Y = análise (0,1)\n",
    "#====================================================================\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset.data, dataset.target, test_size=0.3, random_state=1)\n",
    "\n",
    "print (X_train[0][-50:]  ,  Y_train[0])    \n",
    "print (X_test[0][-50:]  ,  Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#  MultinomialNB\n",
    "#===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 0 0 1]\n",
      "0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# comparar 2 arrays e obter quais coincidem \n",
    "#\n",
    "print(predicted[-10:])\n",
    "print(Y_test[-10:])\n",
    "print(np.mean(predicted[-10:] == Y_test[-10:]))\n",
    "#\n",
    "#\n",
    "\n",
    "np.mean(predicted == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.75      0.80       299\n",
      "         pos       0.78      0.87      0.82       301\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.81      0.81      0.81       600\n",
      "weighted avg       0.81      0.81      0.81       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, predicted,\n",
    "    target_names=dataset.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n",
      "[1 0 1 1 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[224,  75],\n",
       "       [ 39, 262]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# mostra uma matrix com colunas sendo as categorias que quero analisar\n",
    "# e o número de vezes que foi predito na coluna\n",
    "#\n",
    "print( len(Y_test), len(predicted) )\n",
    "print(predicted[-10:])\n",
    "print(Y_test[-10:])\n",
    "#\n",
    "# queremos ver quantos textos eram pos e foram classificados como pos\n",
    "# e quantos eram neg e foram classificados como neg\n",
    "#\n",
    "#\n",
    "metrics.confusion_matrix(Y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#  SGDClassifier\n",
    "#===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 0 0 1]\n",
      "0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8366666666666667"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# comparar 2 arrays e obter quais coincidem \n",
    "#\n",
    "print(predicted[-10:])\n",
    "print(Y_test[-10:])\n",
    "print(np.mean(predicted[-10:] == Y_test[-10:]))\n",
    "#\n",
    "#\n",
    "\n",
    "np.mean(predicted == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.83      0.84       299\n",
      "         pos       0.83      0.84      0.84       301\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, predicted,\n",
    "    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n",
      "[1 0 0 0 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[249,  50],\n",
       "       [ 48, 253]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# mostra uma matrix com colunas sendo as categorias que quero analisar\n",
    "# e o número de vezes que foi predito na coluna\n",
    "#\n",
    "print( len(Y_test), len(predicted) )\n",
    "print(predicted[-10:])\n",
    "print(Y_test[-10:])\n",
    "#\n",
    "# queremos ver quantos textos eram pos e foram classificados como pos\n",
    "# e quantos eram neg e foram classificados como neg\n",
    "#\n",
    "#\n",
    "metrics.confusion_matrix(Y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#  svm.SVC()\n",
    "#===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hical user interface when we use our computers ! \\n' 1\n",
      "b'character , but hartman leaves him in the dust . \\n' 0\n"
     ]
    }
   ],
   "source": [
    "#====================================================================\n",
    "#dvamos separar 30% para teste\n",
    "# X = texto, Y = análise\n",
    "#====================================================================\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset.data, dataset.target, test_size=0.3, random_state=1)\n",
    "\n",
    "print (X_train[0][-50:]  ,  Y_train[0])    \n",
    "print (X_test[0][-50:]  ,  Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', svm.SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 1400\n",
      "b' us a graphical user interface when we use our computers ! \\n'\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( len(X_train), len(Y_train) )\n",
    "print(X_train[0][-60:])\n",
    "print(Y_train[0])\n",
    "\n",
    "text_clf.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 0 0 1]\n",
      "0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7966666666666666"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# comparar 2 arrays e obter quais coincidem \n",
    "#\n",
    "print(predicted[-10:])\n",
    "print(Y_test[-10:])\n",
    "print(np.mean(predicted[-10:] == Y_test[-10:]))\n",
    "#\n",
    "#\n",
    "\n",
    "np.mean(predicted == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.81      0.80       299\n",
      "         pos       0.81      0.78      0.79       301\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.80      0.80      0.80       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, predicted,\n",
    "    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n",
      "[1 0 1 0 1 1 1 1 0 1]\n",
      "[1 0 0 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[242,  57],\n",
       "       [ 65, 236]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# mostra uma matrix com colunas sendo as categorias que quero analisar\n",
    "# e o número de vezes que foi predito na coluna\n",
    "#\n",
    "print( len(Y_test), len(predicted) )\n",
    "print(predicted[-10:])\n",
    "print(Y_test[-10:])\n",
    "#\n",
    "# queremos ver quantos textos eram pos e foram classificados como pos\n",
    "# e quantos eram neg e foram classificados como neg\n",
    "#\n",
    "#\n",
    "metrics.confusion_matrix(Y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#  GridSearchCV() - encontrar os melhores parâmetros por força bruta\n",
    "#\n",
    "# momento da explicacao \n",
    "# https://youtu.be/du_HuGgABtw?t=2997\n",
    "#\n",
    "#===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False)\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names[gs_clf.predict(['xmen'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8099999999999999\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print( gs_clf.best_score_ )                                 \n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
